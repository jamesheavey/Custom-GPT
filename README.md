# Custom-GPT
In this codebase I build a custom Generatively Pretrained Transformer (GPT), following the paper "Attention is All You Need"

In this code base I create a simple transformer using character encoding (rather than sub-word token encoding)
